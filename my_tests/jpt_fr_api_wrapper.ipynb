{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Import sem erros\n"
     ]
    }
   ],
   "source": [
    "import face_recognition as fr\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import math\n",
    "import pickle #Estudar sobre\n",
    "from flask import Flask, render_template, Response\n",
    "print(\"Import sem erros\")\n",
    "\n",
    "\n",
    "def resizeImage(image, **kwargs):\n",
    "    if 'scale' in kwargs.keys():\n",
    "        scale = kwargs.get('scale')\n",
    "        x = int(image.shape[0] * scale)\n",
    "        y = int(image.shape[1] * scale)\n",
    "    return cv2.resize(image, dsize=(x, y), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def compare_images(im1, im2):\n",
    "    plt.Figure(figsize=(10, 10))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(im1)\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(im2)\n",
    "\n",
    "def load_image(path, gray=True):\n",
    "    im = cv2.imread(path)\n",
    "    if gray: im = cv2.cv2tColor(im, cv2.COLOR_BGR2RGB)\n",
    "    return im\n",
    "\n",
    "def flat_images(images):\n",
    "    #Flatten the images array\n",
    "    n, m = images[0].shape\n",
    "    k = len(images)\n",
    "    flat_images = np.zeros((n * m, k), dtype='uint8').T\n",
    "   \n",
    "    for i in range(k):\n",
    "        flat_images[i] = images[i].flatten()\n",
    "    return flat_images\n",
    "\n",
    "\n",
    "def plotSample(images, labels):\n",
    "    size = len(images)\n",
    "    plot_size = np.array(list((3,4))) * 4\n",
    "    plt.figure(figsize=tuple(plot_size))\n",
    "    for i in range(12):\n",
    "        plt.subplot(3,4, i+1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.yticks([])\n",
    "        plt.xticks([])\n",
    "        plt.xlabel(labels[i])\n",
    "    plt.show()\n",
    "   \n",
    "#Lmebrar que esta recebe a predição com distância = True\n",
    "#Errado\n",
    "def get_labels(labels, knn_pred):\n",
    "   names = []\n",
    "   index_pred = [i for i in knn_pred[1][0]]\n",
    "   for i in index_pred:\n",
    "       names.append(labels[i])\n",
    "   return names\n",
    "\n",
    "def read_dir(directory, for_one=False, retrieve_one_image=False):\n",
    "    path = []\n",
    "    images = []\n",
    "    data = []\n",
    "    \n",
    "    if not(for_one):\n",
    "        for sub_folder in os.listdir(directory):\n",
    "            for filename in os.listdir(os.path.join(directory, sub_folder)):\n",
    "                image_path = directory+'/'+sub_folder+'/'+filename\n",
    "                data.append({\"Name\": sub_folder, 'Path': image_path})\n",
    "                if retrieve_one_image:\n",
    "                    break\n",
    "    else:\n",
    "        for image in os.listdir(directory):\n",
    "            image_path = os.path.join(directory,image)\n",
    "            data.append({\"Name\": directory.split('/').pop(), \"Path\":image_path})            \n",
    "     \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def read_image(path):\n",
    "    images = []\n",
    "    for x in path:\n",
    "        im = cv2.imread(x)\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "        images.append(im)\n",
    "    return images\n",
    "\n",
    "\n",
    "def knn_train(X_train, y_train, model_save_path=None, threads=-1):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    n_neighbors = int(math.sqrt(len(X_train))) #Sera susbtituído pelo elbow method\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors= n_neighbors, weights='distance', algorithm='auto', p=2, metric='minkowski', n_jobs = threads)\n",
    "    model.fit(X_train, y_train)\n",
    "    if model_save_path:\n",
    "        save_binary(model, model_save_path)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def knn_predict_(image, model_path=None, verbose=False):\n",
    "    if model_path:\n",
    "        with open(model_path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "   \n",
    "    y_pred = model.kneighbors(image, n_neighbors=1)\n",
    "   \n",
    "    return y_pred\n",
    "\n",
    "def save_binary(model, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "def load_binary(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "def unpaking_array(*args):\n",
    "    new_list = list\n",
    "    \n",
    "    \n",
    "def first_train(train_dir, model_save_path):\n",
    "    df = read_dir(train_dir, retrieve_one_image=True)\n",
    "    df = df.iloc[:1500, :] #Here because of the Dataset \n",
    "    df['Image'] = read_image(df['Path'])\n",
    "    print(df.head(10))\n",
    "\n",
    "    df[\"Face Location\"] = df[\"Image\"].apply(lambda x: fr.face_locations(x, 2, model=\"hog\"))\n",
    "    df[\"Face Encoding\"] = df.apply(lambda x: fr.face_encodings(x[\"Image\"], x[\"Face Location\"]), axis=1)\n",
    "    print(df.head(10))\n",
    "\n",
    "    # model = knn_train([x[0] for x in df['Face Encoding']], df['Name'].values, model_save_path)\n",
    "    model = [x for x in df['Face Encoding']]\n",
    "    return model, df\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando leitura do dataset\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "model_save_path = \"./knn_model.clf\"\n",
    "train_dir = \"archive/lfw-deepfunneled\"\n",
    "df_save_path = 'bkp/dataset_example.csv'\n",
    "# model, df = first_train(train_dir, model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                Name                                               Path  \\\n0        Hugo_Colace  archive/lfw-deepfunneled/Hugo_Colace/Hugo_Cola...   \n1      Alexis_Bledel  archive/lfw-deepfunneled/Alexis_Bledel/Alexis_...   \n2        Jim_Schwarz  archive/lfw-deepfunneled/Jim_Schwarz/Jim_Schwa...   \n3  Patti_Balgojevich  archive/lfw-deepfunneled/Patti_Balgojevich/Pat...   \n4  Yekaterina_Guseva  archive/lfw-deepfunneled/Yekaterina_Guseva/Yek...   \n5        Bruce_Arena  archive/lfw-deepfunneled/Bruce_Arena/Bruce_Are...   \n6      Harland_Braun  archive/lfw-deepfunneled/Harland_Braun/Harland...   \n7         Ken_Wharfe  archive/lfw-deepfunneled/Ken_Wharfe/Ken_Wharfe...   \n8    Anatoliy_Kinakh  archive/lfw-deepfunneled/Anatoliy_Kinakh/Anato...   \n9    Ronald_Young_Jr  archive/lfw-deepfunneled/Ronald_Young_Jr/Ronal...   \n\n                                               Image  \n0  [[[143, 137, 87], [143, 137, 87], [144, 138, 8...  \n1  [[[77, 46, 51], [76, 45, 50], [74, 45, 49], [7...  \n2  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  \n3  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  \n4  [[[4, 1, 0], [3, 1, 0], [190, 189, 168], [183,...  \n5  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  \n6  [[[0, 0, 2], [0, 0, 2], [0, 0, 2], [0, 0, 2], ...  \n7  [[[0, 0, 4], [0, 0, 4], [0, 0, 2], [0, 0, 2], ...  \n8  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  \n9  [[[173, 176, 181], [176, 179, 184], [178, 182,...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = read_dir(train_dir, retrieve_one_image=True)\n",
    "df = df.iloc[:1500, :] #Here because of the Dataset \n",
    "df['Image'] = read_image(df['Path'])\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fim encode\n"
     ]
    }
   ],
   "source": [
    "df[\"Face Location\"] = df[\"Image\"].apply(lambda x: fr.face_locations(x, 2, model=\"hog\"))\n",
    "df[\"Face Encoding\"] = df.apply(lambda x: fr.face_encodings(x[\"Image\"], x[\"Face Location\"]), axis=1)\n",
    "df.to_csv(df_save_path)\n",
    "print(\"Fim encode\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(df_save_path, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       [array([-1.91417083e-01,  1.95971265e-01,  2.9...\n",
       "1       [array([-0.10307143,  0.04149237,  0.05287467,...\n",
       "2       [array([-0.11208726,  0.04770222,  0.03647432,...\n",
       "3       [array([-0.09229631,  0.10290173,  0.06504153,...\n",
       "4       [array([-0.16232829,  0.0982824 ,  0.04514568,...\n",
       "                              ...                        \n",
       "1495    [array([-9.31945816e-02,  1.15615115e-01,  3.9...\n",
       "1496    [array([-9.16979164e-02,  6.33015260e-02,  1.0...\n",
       "1497    [array([-0.10157943,  0.05341316,  0.08426636,...\n",
       "1498    [array([-0.0617888 ,  0.09157034,  0.04556886,...\n",
       "1499    [array([-0.11234332,  0.02471353,  0.12803017,...\n",
       "Name: Face Encoding, Length: 1500, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "df['Face Encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'val'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-fa9dc6685934>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Face Encoding'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Face Encoding'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/env_fr/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5461\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5462\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'val'"
     ]
    }
   ],
   "source": [
    "# model = knn_train([x[0] for x in df['Face Encoding']], df['Name'].values, model_save_path)\n",
    "# model = [x.tolist() for x in df['Face Encoding']]\n",
    "# print(type(df['Face Encoding'][0][0]))\n",
    "# df['Face Encoding'][0][0].tolist()\n",
    "# print(type(model[0]))\n",
    "# extract1 = [x for x in df['Face Encoding']]\n",
    "# extract2 = [x for x in extract1]\n",
    "# extract3 = [x for x in extract2]\n",
    "# extract1[0]\n",
    "\n",
    "new = []\n",
    "kk = [x for x in df['Face Encoding']]\n",
    "df.dtypes\n",
    "q = df['Face Encoding'].to_numpy()\n",
    "\n",
    "q\n",
    "# new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-021ff0978fb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mextract2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "extract2[0][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([-1.91417083e-01,  1.95971265e-01,  2.98056640e-02, -1.40309753e-03,\n",
       "        -1.62832886e-01,  5.73441423e-02,  2.68988498e-02, -7.83351064e-02,\n",
       "         1.19494982e-01,  2.48833857e-02,  2.14858279e-01, -1.61701068e-02,\n",
       "        -3.00058275e-01, -1.54402955e-02, -8.53237063e-02,  7.82236904e-02,\n",
       "        -1.30104274e-01, -1.51656300e-01, -1.30642578e-01, -6.25630170e-02,\n",
       "         1.28162161e-01,  3.90405729e-02, -5.65032102e-02,  6.30049407e-02,\n",
       "        -2.13056833e-01, -3.15944254e-01, -7.68395737e-02, -1.44707244e-02,\n",
       "         8.17304775e-02, -1.40941784e-01, -9.08156857e-04,  1.73249207e-02,\n",
       "        -1.96565345e-01, -4.75858562e-02,  3.14136371e-02,  6.17821515e-02,\n",
       "        -1.36305420e-02, -5.47061153e-02,  2.33899742e-01, -3.51284072e-03,\n",
       "        -1.41272202e-01,  8.32951069e-02,  1.25700638e-01,  3.24241579e-01,\n",
       "         1.36166394e-01, -1.42994476e-02,  2.39175074e-02, -5.41552939e-02,\n",
       "         1.03554986e-01, -2.50845939e-01,  6.54276162e-02,  1.88776270e-01,\n",
       "         1.74143642e-01,  6.93112314e-02,  8.68806913e-02, -1.88598171e-01,\n",
       "        -8.15158635e-02,  1.98954269e-01, -1.67153046e-01,  1.10632688e-01,\n",
       "         5.54222167e-02, -1.11576997e-01, -8.12260062e-02, -1.58477306e-01,\n",
       "         1.00858279e-01,  9.25120935e-02, -1.06465235e-01, -1.74296021e-01,\n",
       "         1.39662221e-01, -1.08712718e-01, -1.94984935e-02,  8.94642994e-02,\n",
       "        -6.89767450e-02, -1.56663284e-01, -2.52092808e-01,  1.28782600e-01,\n",
       "         4.64644939e-01,  1.79254949e-01, -2.22641617e-01, -1.13478079e-02,\n",
       "        -7.02659041e-02, -2.99880989e-02,  2.30019428e-02, -4.92333062e-02,\n",
       "        -1.38138697e-01, -5.02118059e-02, -1.58805743e-01,  1.31928682e-01,\n",
       "         2.11498350e-01,  4.96027097e-02,  7.61572970e-03,  1.97169811e-01,\n",
       "         9.34295431e-02,  2.70074997e-02,  2.93594375e-02,  4.38130200e-02,\n",
       "        -1.75473019e-01, -2.86518149e-02, -1.23848133e-01,  4.14347872e-02,\n",
       "        -1.82903539e-02, -1.01828463e-01,  2.83702239e-02,  8.56849924e-02,\n",
       "        -1.20738506e-01,  1.41195163e-01,  4.54975441e-02, -4.64035347e-02,\n",
       "        -9.70395803e-02, -1.85961835e-06, -1.58968359e-01,  5.32254875e-02,\n",
       "         1.50577039e-01, -2.97946900e-01,  2.01671511e-01,  1.07124254e-01,\n",
       "         8.25999957e-03,  1.27544761e-01,  1.13620065e-01,  2.40644030e-02,\n",
       "         2.23348103e-02, -4.87508811e-03, -1.12518512e-01, -1.03989825e-01,\n",
       "         1.03930607e-01, -1.16519839e-01,  8.08396861e-02,  9.26502235e-03])]"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "extract3[0]"
   ]
  }
 ]
}