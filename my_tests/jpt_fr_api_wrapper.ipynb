{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Import sem erros\n"
     ]
    }
   ],
   "source": [
    "import face_recognition as fr\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import math\n",
    "import pickle #Estudar sobre\n",
    "from flask import Flask, render_template, Response\n",
    "print(\"Import sem erros\")\n",
    "\n",
    "\n",
    "def resizeImage(image, **kwargs):\n",
    "    if 'scale' in kwargs.keys():\n",
    "        scale = kwargs.get('scale')\n",
    "        x = int(image.shape[0] * scale)\n",
    "        y = int(image.shape[1] * scale)\n",
    "    return cv2.resize(image, dsize=(x, y), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def compare_images(im1, im2):\n",
    "    plt.Figure(figsize=(10, 10))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(im1)\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(im2)\n",
    "\n",
    "def load_image(path, gray=True):\n",
    "    im = cv2.imread(path)\n",
    "    if gray: im = cv2.cv2tColor(im, cv2.COLOR_BGR2RGB)\n",
    "    return im\n",
    "\n",
    "def flat_images(images):\n",
    "    #Flatten the images array\n",
    "    n, m = images[0].shape\n",
    "    k = len(images)\n",
    "    flat_images = np.zeros((n * m, k), dtype='uint8').T\n",
    "   \n",
    "    for i in range(k):\n",
    "        flat_images[i] = images[i].flatten()\n",
    "    return flat_images\n",
    "\n",
    "\n",
    "def plotSample(images, labels):\n",
    "    size = len(images)\n",
    "    plot_size = np.array(list((3,4))) * 4\n",
    "    plt.figure(figsize=tuple(plot_size))\n",
    "    for i in range(12):\n",
    "        plt.subplot(3,4, i+1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.yticks([])\n",
    "        plt.xticks([])\n",
    "        plt.xlabel(labels[i])\n",
    "    plt.show()\n",
    "   \n",
    "#Lmebrar que esta recebe a predição com distância = True\n",
    "#Errado\n",
    "def get_labels(labels, knn_pred):\n",
    "   names = []\n",
    "   index_pred = [i for i in knn_pred[1][0]]\n",
    "   for i in index_pred:\n",
    "       names.append(labels[i])\n",
    "   return names\n",
    "\n",
    "def read_dir(directory, for_one=False, retrieve_one_image=False):\n",
    "    path = []\n",
    "    images = []\n",
    "    data = []\n",
    "    \n",
    "    if not(for_one):\n",
    "        for sub_folder in os.listdir(directory):\n",
    "            for filename in os.listdir(os.path.join(directory, sub_folder)):\n",
    "                image_path = directory+'/'+sub_folder+'/'+filename\n",
    "                data.append({\"Name\": sub_folder, 'Path': image_path})\n",
    "                if retrieve_one_image:\n",
    "                    break\n",
    "    else:\n",
    "        for image in os.listdir(directory):\n",
    "            image_path = os.path.join(directory,image)\n",
    "            data.append({\"Name\": directory.split('/').pop(), \"Path\":image_path})            \n",
    "     \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def read_image(path):\n",
    "    images = []\n",
    "    for x in path:\n",
    "        im = cv2.imread(x)\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "        images.append(im)\n",
    "    return images\n",
    "\n",
    "\n",
    "def knn_train(X_train, y_train, model_save_path=None, threads=-1):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    n_neighbors = int(math.sqrt(len(X_train))) #Sera susbtituído pelo elbow method\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors= n_neighbors, weights='distance', algorithm='auto', p=2, metric='minkowski', n_jobs = threads)\n",
    "    model.fit(X_train, y_train)\n",
    "    if model_save_path:\n",
    "        save_binary(model, model_save_path)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def knn_predict_(image, model_path=None, verbose=False):\n",
    "    if model_path:\n",
    "        with open(model_path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "   \n",
    "    y_pred = model.kneighbors(image, n_neighbors=1)\n",
    "   \n",
    "    return y_pred\n",
    "\n",
    "def save_binary(model, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "def load_binary(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "def unpaking_array(*args):\n",
    "    new_list = list\n",
    "    \n",
    "    \n",
    "def first_train(train_dir, model_save_path):\n",
    "    df = read_dir(train_dir, retrieve_one_image=True)\n",
    "    df = df.iloc[:1500, :] #Here because of the Dataset \n",
    "    df['Image'] = read_image(df['Path'])\n",
    "    print(df.head(10))\n",
    "\n",
    "    df[\"Face Location\"] = df[\"Image\"].apply(lambda x: fr.face_locations(x, 2, model=\"hog\"))\n",
    "    df[\"Face Encoding\"] = df.apply(lambda x: fr.face_encodings(x[\"Image\"], x[\"Face Location\"]), axis=1)\n",
    "    print(df.head(10))\n",
    "\n",
    "    # model = knn_train([x[0] for x in df['Face Encoding']], df['Name'].values, model_save_path)\n",
    "    model = [x for x in df['Face Encoding']]\n",
    "    return model, df\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando leitura do dataset\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "model_save_path = \"./knn_model.clf\"\n",
    "train_dir = \"archive/lfw-deepfunneled\"\n",
    "df_save_path = 'bkp/dataset_example.pkl'\n",
    "\n",
    "\n",
    "# model, df = first_train(train_dir, model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                Name                                               Path  \\\n0        Hugo_Colace  archive/lfw-deepfunneled/Hugo_Colace/Hugo_Cola...   \n1      Alexis_Bledel  archive/lfw-deepfunneled/Alexis_Bledel/Alexis_...   \n2        Jim_Schwarz  archive/lfw-deepfunneled/Jim_Schwarz/Jim_Schwa...   \n3  Patti_Balgojevich  archive/lfw-deepfunneled/Patti_Balgojevich/Pat...   \n4  Yekaterina_Guseva  archive/lfw-deepfunneled/Yekaterina_Guseva/Yek...   \n5        Bruce_Arena  archive/lfw-deepfunneled/Bruce_Arena/Bruce_Are...   \n6      Harland_Braun  archive/lfw-deepfunneled/Harland_Braun/Harland...   \n7         Ken_Wharfe  archive/lfw-deepfunneled/Ken_Wharfe/Ken_Wharfe...   \n8    Anatoliy_Kinakh  archive/lfw-deepfunneled/Anatoliy_Kinakh/Anato...   \n9    Ronald_Young_Jr  archive/lfw-deepfunneled/Ronald_Young_Jr/Ronal...   \n\n                                               Image  \n0  [[[143, 137, 87], [143, 137, 87], [144, 138, 8...  \n1  [[[77, 46, 51], [76, 45, 50], [74, 45, 49], [7...  \n2  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  \n3  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  \n4  [[[4, 1, 0], [3, 1, 0], [190, 189, 168], [183,...  \n5  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  \n6  [[[0, 0, 2], [0, 0, 2], [0, 0, 2], [0, 0, 2], ...  \n7  [[[0, 0, 4], [0, 0, 4], [0, 0, 2], [0, 0, 2], ...  \n8  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  \n9  [[[173, 176, 181], [176, 179, 184], [178, 182,...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = read_dir(train_dir, retrieve_one_image=True)\n",
    "df = df.iloc[:1500, :] #Here because of the Dataset \n",
    "df['Image'] = read_image(df['Path'])\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fim encode\n"
     ]
    }
   ],
   "source": [
    "df[\"Face Location\"] = df[\"Image\"].apply(lambda x: fr.face_locations(x, 2, model=\"hog\"))\n",
    "df[\"Face Encoding\"] = df.apply(lambda x: fr.face_encodings(x[\"Image\"], x[\"Face Location\"]), axis=1)\n",
    "df.to_pickle(df_save_path) #parquet does not support 2D arrays\n",
    "print(\"Fim encode\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(df_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1500 entries, 0 to 1499\nData columns (total 5 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   Name           1500 non-null   object\n 1   Path           1500 non-null   object\n 2   Image          1500 non-null   object\n 3   Face Location  1500 non-null   object\n 4   Face Encoding  1500 non-null   object\ndtypes: object(5)\nmemory usage: 58.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(df_save_path)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1500 entries, 0 to 1499\nData columns (total 5 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   Name           1500 non-null   object\n 1   Path           1500 non-null   object\n 2   Image          1500 non-null   object\n 3   Face Location  1500 non-null   object\n 4   Face Encoding  1500 non-null   object\ndtypes: object(5)\nmemory usage: 58.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_2 = df.copy()\n",
    "df_2.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'iterrows'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-009763749966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Face Location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/env_fr/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5461\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5462\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'iterrows'"
     ]
    }
   ],
   "source": [
    "kk = df['Face Location'].iterrows()\n",
    "for item in kk:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "588\n[-1.40803248e-01  7.86165968e-02  6.62570866e-03 -5.87223396e-02\n -6.92278966e-02 -3.82894091e-02 -4.40395735e-02 -1.10197149e-01\n  1.34513855e-01  1.57549027e-02  1.39137194e-01 -7.28460625e-02\n -2.57932097e-01  4.54097055e-04 -1.16960108e-01  9.59389806e-02\n -1.55617461e-01 -1.09792896e-01 -1.87494308e-02 -1.95994899e-02\n  5.90403080e-02  5.39695919e-02 -5.16973436e-02  6.09443113e-02\n -1.04232766e-01 -2.80124128e-01 -1.05995528e-01 -7.78064728e-02\n  2.04362161e-02 -8.11036453e-02 -2.84332763e-02  7.34889731e-02\n -1.92726180e-01 -6.32749423e-02  3.74213383e-02  1.76160544e-01\n -2.65048984e-02  1.24252848e-02  1.15373716e-01  1.07576549e-01\n -8.89127329e-02 -4.36579734e-02  8.35225806e-02  3.84131819e-01\n  1.38959259e-01  5.27912863e-02 -8.18355195e-03  3.93852405e-03\n  3.67053114e-02 -2.85501212e-01  1.07814036e-01  1.58008724e-01\n  1.53121248e-01  1.13862582e-01  1.29191548e-01 -2.19440624e-01\n  2.92721763e-02  1.18769661e-01 -1.81706145e-01  1.63930342e-01\n  7.66438916e-02  1.19234016e-02 -1.99108217e-02 -2.22418681e-02\n  1.80426687e-01  1.02746688e-01 -1.00886263e-01 -7.65175596e-02\n  1.23137638e-01 -1.44935668e-01 -4.15400416e-02 -8.66502151e-03\n -8.79321918e-02 -2.00001687e-01 -2.66169786e-01  6.28002211e-02\n  3.08441967e-01  1.40036553e-01 -2.14614943e-01  3.06883194e-02\n -1.11963702e-02 -3.00841630e-02  1.16424039e-01 -4.19163816e-02\n -5.82573339e-02  7.03556612e-02 -1.37164265e-01  1.21516669e-02\n  1.55310169e-01 -2.69811526e-02  3.18110175e-02  2.05385655e-01\n -2.73751393e-02 -6.45752624e-02  7.22377896e-02  6.64490536e-02\n -7.12300614e-02  1.37869339e-03 -1.79314330e-01 -1.51762255e-02\n  4.70627546e-02 -1.77863151e-01 -3.58957388e-02  4.95796651e-02\n -1.98198482e-01  8.81851092e-02  8.12112466e-02 -6.64496422e-02\n -9.25016478e-02 -2.20350064e-02 -2.08746850e-01 -1.21227708e-02\n  2.30616570e-01 -2.68499851e-01  2.51596361e-01  2.00903788e-01\n -3.62701938e-02  1.36675954e-01  4.61146161e-02  4.31292430e-02\n  3.01785059e-02 -3.51796225e-02 -1.81134660e-02 -1.18375026e-01\n -1.81015115e-04 -8.38483032e-03 -6.51632845e-02  4.84818220e-02]\n520\n[-0.15898155  0.08770677  0.07145309 -0.02315842 -0.03946196 -0.09492134\n  0.11966507 -0.12066229  0.18725286 -0.01832131  0.30503321 -0.0285337\n -0.17142971 -0.17153382 -0.02340813  0.12322449 -0.16037916 -0.13897549\n -0.03860155 -0.10290223  0.0181453  -0.06215091  0.02444047  0.04213605\n -0.10232809 -0.36197251 -0.07650039 -0.19378823  0.02502502 -0.05784969\n  0.1660565   0.13329311 -0.10084709 -0.05261967  0.00953151  0.03546348\n  0.04808374  0.02984167  0.21584323 -0.03600343 -0.1161399  -0.01680311\n  0.01355299  0.36012796  0.08243872  0.02057303  0.09378449 -0.01721061\n  0.13814203 -0.23601779  0.02233418  0.06812577  0.1759523  -0.03126233\n  0.09802833 -0.11399315  0.01065801  0.08346984 -0.249009    0.12217191\n  0.04555697 -0.0891727  -0.1056354  -0.04324893  0.27911574  0.12069131\n -0.13974516 -0.04790363  0.20347591 -0.07815146 -0.0336653   0.0565153\n -0.14278828 -0.13966574 -0.25671563  0.07176188  0.47127816  0.08645589\n -0.18987441 -0.01406208 -0.19216448  0.10175156 -0.01092864  0.01015032\n -0.14679423 -0.01374815 -0.14875919 -0.03156206  0.12096635 -0.00737979\n -0.09428173  0.18366934 -0.02436634  0.01523018 -0.03213394 -0.05030895\n -0.06548901 -0.01132271 -0.08444224 -0.07508672  0.07642338 -0.09314422\n  0.03529526  0.05389213 -0.27012083  0.13350916 -0.01407419  0.03075857\n  0.01568648  0.09301222 -0.05134381  0.0151493   0.14889282 -0.27365577\n  0.21877952  0.17865321  0.01829171  0.17136078  0.018967    0.00850261\n -0.04667794 -0.04633985 -0.06733264 -0.07031839  0.04229435 -0.02135475\n  0.04035423  0.02335867]\n369\n[-0.14381099  0.05245985 -0.01922641 -0.06619205 -0.11193065 -0.02063811\n -0.01842231 -0.02902589  0.1426349   0.01719704  0.1464259  -0.02504488\n -0.20366165 -0.02785062 -0.0734802   0.07601025 -0.20515816 -0.06940168\n -0.1218887  -0.09869794 -0.03394501  0.06512199  0.07953123  0.01086841\n -0.12401259 -0.36238748 -0.09602994 -0.2214835   0.09954409 -0.14071512\n  0.09887636  0.03843204 -0.15387738 -0.08755535  0.06674045  0.02717532\n -0.10742    -0.01529297  0.24649575  0.04160515 -0.10641015 -0.02825987\n  0.05076434  0.37794876  0.2662459   0.04299629  0.02775705 -0.05350079\n  0.11914418 -0.28519207  0.10498421  0.13306746  0.07515951  0.08193547\n  0.17506973 -0.08162594  0.03986326  0.10879232 -0.21144187  0.12457245\n  0.0698895  -0.00251891 -0.07156345 -0.02990633  0.18412018  0.03203714\n -0.1155665  -0.10666198  0.2057403  -0.1728861   0.01579427  0.1182348\n -0.10784834 -0.18632977 -0.24704556  0.02840609  0.38501835  0.12678216\n -0.08109983 -0.00626827 -0.05525756 -0.07677515  0.00789115  0.03055206\n -0.10860243 -0.06741866  0.00267017  0.09708183  0.14759186 -0.03236109\n -0.0459538   0.16928753 -0.02380554 -0.07078604  0.04743911  0.06225291\n -0.08929136 -0.02953156 -0.1202271   0.01423306  0.09180228 -0.136269\n  0.00952243  0.07583991 -0.17254637  0.16050249 -0.01112848 -0.07230207\n -0.05018546 -0.08559662 -0.12524198  0.05658786  0.26092744 -0.27489927\n  0.27163976  0.20358589  0.01359315  0.10288999 -0.00941419 -0.03820608\n -0.00723659 -0.00240093 -0.13931315 -0.08501718 -0.02760612 -0.02337384\n -0.02775707 -0.00560141]\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(df['Face Location'][:13], df['Face Encoding'][:13]):\n",
    "    if len(x) > 1:\n",
    "        list(x)\n",
    "        for x1, y1 in zip(x, y):\n",
    "            print(sum(x1))\n",
    "            print(y1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(57, 237, 134, 160), (89, 171, 182, 78), (109, 74, 186, 0)]\n"
     ]
    }
   ],
   "source": [
    "soma = lambda x: sum(x)\n",
    "sum_list_loc_m = []\n",
    "for x, y in zip(df_2['Face Location'][:13], df_2['Face Encoding'][:13]):\n",
    "    if len(x) > 1:\n",
    "        list_locations_m = list(x)\n",
    "        for loc in list_locations_m:\n",
    "            sum_list_loc_m.append(loc)\n",
    "        sum_list_loc_m.sort(key=soma, reverse=True)\n",
    "        print(sum_list_loc_m)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "((57, 237, 134, 160), array([-1.40803248e-01,  7.86165968e-02,  6.62570866e-03, -5.87223396e-02,\n       -6.92278966e-02, -3.82894091e-02, -4.40395735e-02, -1.10197149e-01,\n        1.34513855e-01,  1.57549027e-02,  1.39137194e-01, -7.28460625e-02,\n       -2.57932097e-01,  4.54097055e-04, -1.16960108e-01,  9.59389806e-02,\n       -1.55617461e-01, -1.09792896e-01, -1.87494308e-02, -1.95994899e-02,\n        5.90403080e-02,  5.39695919e-02, -5.16973436e-02,  6.09443113e-02,\n       -1.04232766e-01, -2.80124128e-01, -1.05995528e-01, -7.78064728e-02,\n        2.04362161e-02, -8.11036453e-02, -2.84332763e-02,  7.34889731e-02,\n       -1.92726180e-01, -6.32749423e-02,  3.74213383e-02,  1.76160544e-01,\n       -2.65048984e-02,  1.24252848e-02,  1.15373716e-01,  1.07576549e-01,\n       -8.89127329e-02, -4.36579734e-02,  8.35225806e-02,  3.84131819e-01,\n        1.38959259e-01,  5.27912863e-02, -8.18355195e-03,  3.93852405e-03,\n        3.67053114e-02, -2.85501212e-01,  1.07814036e-01,  1.58008724e-01,\n        1.53121248e-01,  1.13862582e-01,  1.29191548e-01, -2.19440624e-01,\n        2.92721763e-02,  1.18769661e-01, -1.81706145e-01,  1.63930342e-01,\n        7.66438916e-02,  1.19234016e-02, -1.99108217e-02, -2.22418681e-02,\n        1.80426687e-01,  1.02746688e-01, -1.00886263e-01, -7.65175596e-02,\n        1.23137638e-01, -1.44935668e-01, -4.15400416e-02, -8.66502151e-03,\n       -8.79321918e-02, -2.00001687e-01, -2.66169786e-01,  6.28002211e-02,\n        3.08441967e-01,  1.40036553e-01, -2.14614943e-01,  3.06883194e-02,\n       -1.11963702e-02, -3.00841630e-02,  1.16424039e-01, -4.19163816e-02,\n       -5.82573339e-02,  7.03556612e-02, -1.37164265e-01,  1.21516669e-02,\n        1.55310169e-01, -2.69811526e-02,  3.18110175e-02,  2.05385655e-01,\n       -2.73751393e-02, -6.45752624e-02,  7.22377896e-02,  6.64490536e-02,\n       -7.12300614e-02,  1.37869339e-03, -1.79314330e-01, -1.51762255e-02,\n        4.70627546e-02, -1.77863151e-01, -3.58957388e-02,  4.95796651e-02,\n       -1.98198482e-01,  8.81851092e-02,  8.12112466e-02, -6.64496422e-02,\n       -9.25016478e-02, -2.20350064e-02, -2.08746850e-01, -1.21227708e-02,\n        2.30616570e-01, -2.68499851e-01,  2.51596361e-01,  2.00903788e-01,\n       -3.62701938e-02,  1.36675954e-01,  4.61146161e-02,  4.31292430e-02,\n        3.01785059e-02, -3.51796225e-02, -1.81134660e-02, -1.18375026e-01,\n       -1.81015115e-04, -8.38483032e-03, -6.51632845e-02,  4.84818220e-02]))\n"
     ]
    }
   ],
   "source": [
    "sum_list_loc_m = []\n",
    "result = zip(df_2['Face Location'][:13], df_2['Face Encoding'][:13])\n",
    "for face_location, face_encoding in result:\n",
    "    if len(face_location) > 1:\n",
    "        mydict = dict(zip(face_location, face_encoding))\n",
    "        sorted_dict = dict()\n",
    "        for key in sorted(mydict, key=lambda x: sum(x), reverse=True):\n",
    "            sorted_dict.update({key: mydict[key]})\n",
    "\n",
    "first = next(iter(mydict_2.items()))\n",
    "print(first)\n",
    "x, y = first\n",
    "print(x)\n",
    "print(y)\n",
    "  \n",
    "        # res = zip(face_location, face_encoding)\n",
    "        # res_set = dict(res)\n",
    "        # for x, y in res_set:\n",
    "        #     print(x)\n",
    "        #     print(y)\n",
    "        # sum_list_loc_m = list(face_location)\n",
    "        # sum_list_loc_m.sort(key=lambda x: sum(x), reverse=True)\n",
    "        # print(sum_list_loc_m)\n",
    "\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'function' object is not iterable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-cc9ecc65c415>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# sub_frame = df_2.loc[lambda x: x['Face Location'] > 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Face Location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mkk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/env_fr/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, items, like, regex, axis)\u001b[0m\n\u001b[1;32m   4971\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4972\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4973\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4974\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'function' object is not iterable"
     ]
    }
   ],
   "source": [
    "# sub_frame = df_2.loc[lambda x: x['Face Location'] > 1]\n",
    "kk = df_2['Face Location'].filter(lambda x: len(x) > 1)\n",
    "kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[12]\n",
    "test_m = zip(df['Face Location'][12], df['Face Encoding'][12])\n",
    "test_o = zip(df['Face Location'][13], df['Face Encoding'][13])\n",
    "# este são os valores recebidos continuamente pelo serão zipados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "len_zip = sum(1 for _ in test_m)\n",
    "if len_zip > 1:\n",
    "    encodings = []\n",
    "    for location, encoding in test_m:\n",
    "        encodings.append(encoding)\n",
    "        print(location)\n",
    "\n",
    "    print(encodings)\n",
    "    # y_pred = model.predict(encodings)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc, enc in test_m:\n",
    "        print(loc)\n",
    "        print(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<zip at 0x7f0a7a9a7980>"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "test_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Devo retornar um array com as posições de cada face e seus nomes para que o draw possa iterar neste, mesmo que seja unitário\n",
    "#No momento do cadastro a screenshot deverá ser validada, para que se armazene somente a foto que houver apenas uma face\n",
    "model = knn_train()...\n",
    "y_pred = model.predict(frame_encoded)\n",
    "candidate = df[df['Name'] == y_pred]\n",
    "face_distance = can\n"
   ]
  }
 ]
}