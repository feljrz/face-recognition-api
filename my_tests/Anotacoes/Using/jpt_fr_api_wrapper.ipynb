{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Import sem erros\n"
     ]
    }
   ],
   "source": [
    "#Testando o o que será colocado em threads_cam.py\n",
    "\n",
    "\n",
    "import face_recognition as fr\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import math\n",
    "import pickle #Estudar sobre\n",
    "from flask import Flask, render_template, Response\n",
    "\n",
    "\n",
    "\n",
    "def resizeImage(image, **kwargs):\n",
    "    if 'scale' in kwargs.keys():\n",
    "        scale = kwargs.get('scale')\n",
    "        x = int(image.shape[0] * scale)\n",
    "        y = int(image.shape[1] * scale)\n",
    "    return cv2.resize(image, dsize=(x, y), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def compare_images(im1, im2):\n",
    "    plt.Figure(figsize=(10, 10))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(im1)\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(im2)\n",
    "\n",
    "def load_image(path, gray=True):\n",
    "    im = cv2.imread(path)\n",
    "    if gray: im = cv2.cv2tColor(im, cv2.COLOR_BGR2RGB)\n",
    "    return im\n",
    "\n",
    "def flat_images(images):\n",
    "    #Flatten the images array\n",
    "    n, m = images[0].shape\n",
    "    k = len(images)\n",
    "    flat_images = np.zeros((n * m, k), dtype='uint8').T\n",
    "   \n",
    "    for i in range(k):\n",
    "        flat_images[i] = images[i].flatten()\n",
    "    return flat_images\n",
    "\n",
    "\n",
    "def plotSample(images, labels):\n",
    "    size = len(images)\n",
    "    plot_size = np.array(list((3,4))) * 4\n",
    "    plt.figure(figsize=tuple(plot_size))\n",
    "    for i in range(12):\n",
    "        plt.subplot(3,4, i+1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.yticks([])\n",
    "        plt.xticks([])\n",
    "        plt.xlabel(labels[i])\n",
    "    plt.show()\n",
    "   \n",
    "#Lmebrar que esta recebe a predição com distância = True\n",
    "#Errado\n",
    "def get_labels(labels, knn_pred):\n",
    "   names = []\n",
    "   index_pred = [i for i in knn_pred[1][0]]\n",
    "   for i in index_pred:\n",
    "       names.append(labels[i])\n",
    "   return names\n",
    "\n",
    "def read_dir(directory, for_one=False, retrieve_one_image=False):\n",
    "    path = []\n",
    "    images = []\n",
    "    data = []\n",
    "    \n",
    "    if not(for_one):\n",
    "        for sub_folder in os.listdir(directory):\n",
    "            for filename in os.listdir(os.path.join(directory, sub_folder)):\n",
    "                image_path = directory+'/'+sub_folder+'/'+filename\n",
    "                data.append({\"Name\": sub_folder, 'Path': image_path})\n",
    "                if retrieve_one_image:\n",
    "                    break\n",
    "    else:\n",
    "        for image in os.listdir(directory):\n",
    "            image_path = os.path.join(directory,image)\n",
    "            data.append({\"Name\": directory.split('/').pop(), \"Path\":image_path})            \n",
    "     \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def read_image(path):\n",
    "    images = []\n",
    "    for x in path:\n",
    "        im = cv2.imread(x)\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "        images.append(im)\n",
    "    return images\n",
    "\n",
    "\n",
    "def knn_train(X_train, y_train, model_save_path=None, threads=-1):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    n_neighbors = int(math.sqrt(len(X_train))) #Sera susbtituído pelo elbow method\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors= n_neighbors, weights='distance', algorithm='auto', p=2, metric='minkowski', n_jobs = threads)\n",
    "    model.fit(X_train, y_train)\n",
    "    if model_save_path:\n",
    "        save_binary(model, model_save_path)\n",
    "    print(\"End of training\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def knn_predict_(image, model_path=None, verbose=False):\n",
    "    if model_path:\n",
    "        with open(model_path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "   \n",
    "    y_pred = model.kneighbors(image, n_neighbors=1)\n",
    "   \n",
    "    return y_pred\n",
    "\n",
    "def save_binary(model, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "def load_binary(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "def unpaking_array(*args):\n",
    "    new_list = list\n",
    "    \n",
    "    \n",
    "def first_train(train_dir, model_save_path):\n",
    "    df = read_dir(train_dir, retrieve_one_image=True)\n",
    "    df = df.sort_values([\"Name\"]) #@@@ Here because of the Dataset @@@\n",
    "    df = df.iloc[:1500, :] #@@@ Here because of the Dataset @@@\n",
    "    df['Image'] = read_image(df['Path'])\n",
    "    print(df.head(10))\n",
    "    \n",
    "    df[\"Face Location\"] = df[\"Image\"].apply(lambda x: fr.face_locations(x, 2, model=\"hog\"))\n",
    "    df[\"Face Encoding\"] = df.apply(lambda x: fr.face_encodings(x[\"Image\"], x[\"Face Location\"]), axis=1)\n",
    "    df = df[df.apply(lambda x: len(x['Face Encoding']) == 1, axis= 1)] #@@@@ Here because of the Dataset @@@\n",
    "    print(df.head(10))\n",
    "\n",
    "    #Encode array has to be a 'pure' array to sklearn train\n",
    "    X_train = []\n",
    "    for elem in df['Face Encoding'].values:\n",
    "        X_train.append(elem[0]) \n",
    "\n",
    "    model = knn_train(X_train, df['Name'].values, model_save_path)\n",
    "    print(\"End of first train\")\n",
    "    return model, df\n",
    "\n",
    "model_save_path = \"./knn_model.clf\"\n",
    "train_dir = \"archive/lfw-deepfunneled\"\n",
    "df_save_path = 'bkp/dataset_example.pkl'\n",
    "\n",
    "print(\"Import sem erros\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 Name                                               Path  \\\n",
      "3985  AFelipe_Rezende     archive/lfw-deepfunneled/AFelipe_Rezende/1.jpg   \n",
      "3938          AJ_Cook  archive/lfw-deepfunneled/AJ_Cook/AJ_Cook_0001.jpg   \n",
      "2612         AJ_Lamas  archive/lfw-deepfunneled/AJ_Lamas/AJ_Lamas_000...   \n",
      "4259    Aaron_Eckhart  archive/lfw-deepfunneled/Aaron_Eckhart/Aaron_E...   \n",
      "4671      Aaron_Guiel  archive/lfw-deepfunneled/Aaron_Guiel/Aaron_Gui...   \n",
      "4134  Aaron_Patterson  archive/lfw-deepfunneled/Aaron_Patterson/Aaron...   \n",
      "1454    Aaron_Peirsol  archive/lfw-deepfunneled/Aaron_Peirsol/Aaron_P...   \n",
      "1920       Aaron_Pena  archive/lfw-deepfunneled/Aaron_Pena/Aaron_Pena...   \n",
      "2177     Aaron_Sorkin  archive/lfw-deepfunneled/Aaron_Sorkin/Aaron_So...   \n",
      "1095     Aaron_Tippin  archive/lfw-deepfunneled/Aaron_Tippin/Aaron_Ti...   \n",
      "\n",
      "                                                  Image  \n",
      "3985  [[[201, 196, 200], [201, 196, 200], [201, 196,...  \n",
      "3938  [[[0, 5, 0], [0, 4, 0], [0, 1, 4], [0, 1, 5], ...  \n",
      "2612  [[[1, 2, 7], [0, 1, 6], [8, 7, 12], [0, 0, 2],...  \n",
      "4259  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  \n",
      "4671  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  \n",
      "4134  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  \n",
      "1454  [[[11, 11, 11], [11, 11, 11], [11, 11, 11], [1...  \n",
      "1920  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  \n",
      "2177  [[[247, 240, 224], [247, 240, 224], [247, 240,...  \n",
      "1095  [[[0, 4, 0], [0, 4, 0], [0, 4, 0], [0, 4, 0], ...  \n",
      "                 Name                                               Path  \\\n",
      "3985  AFelipe_Rezende     archive/lfw-deepfunneled/AFelipe_Rezende/1.jpg   \n",
      "3938          AJ_Cook  archive/lfw-deepfunneled/AJ_Cook/AJ_Cook_0001.jpg   \n",
      "2612         AJ_Lamas  archive/lfw-deepfunneled/AJ_Lamas/AJ_Lamas_000...   \n",
      "4259    Aaron_Eckhart  archive/lfw-deepfunneled/Aaron_Eckhart/Aaron_E...   \n",
      "4671      Aaron_Guiel  archive/lfw-deepfunneled/Aaron_Guiel/Aaron_Gui...   \n",
      "4134  Aaron_Patterson  archive/lfw-deepfunneled/Aaron_Patterson/Aaron...   \n",
      "1454    Aaron_Peirsol  archive/lfw-deepfunneled/Aaron_Peirsol/Aaron_P...   \n",
      "1920       Aaron_Pena  archive/lfw-deepfunneled/Aaron_Pena/Aaron_Pena...   \n",
      "2177     Aaron_Sorkin  archive/lfw-deepfunneled/Aaron_Sorkin/Aaron_So...   \n",
      "1095     Aaron_Tippin  archive/lfw-deepfunneled/Aaron_Tippin/Aaron_Ti...   \n",
      "\n",
      "                                                  Image  \\\n",
      "3985  [[[201, 196, 200], [201, 196, 200], [201, 196,...   \n",
      "3938  [[[0, 5, 0], [0, 4, 0], [0, 1, 4], [0, 1, 5], ...   \n",
      "2612  [[[1, 2, 7], [0, 1, 6], [8, 7, 12], [0, 0, 2],...   \n",
      "4259  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...   \n",
      "4671  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...   \n",
      "4134  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...   \n",
      "1454  [[[11, 11, 11], [11, 11, 11], [11, 11, 11], [1...   \n",
      "1920  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...   \n",
      "2177  [[[247, 240, 224], [247, 240, 224], [247, 240,...   \n",
      "1095  [[[0, 4, 0], [0, 4, 0], [0, 4, 0], [0, 4, 0], ...   \n",
      "\n",
      "                Face Location  \\\n",
      "3985  [(625, 816, 1201, 241)]   \n",
      "3938     [(70, 181, 182, 70)]   \n",
      "2612     [(83, 181, 194, 70)]   \n",
      "4259     [(89, 171, 182, 78)]   \n",
      "4671     [(89, 171, 182, 78)]   \n",
      "4134     [(89, 171, 182, 78)]   \n",
      "1454     [(83, 181, 194, 70)]   \n",
      "1920     [(83, 181, 194, 70)]   \n",
      "2177     [(83, 181, 194, 70)]   \n",
      "1095     [(70, 181, 182, 70)]   \n",
      "\n",
      "                                          Face Encoding  \n",
      "3985  [[-0.13103333115577698, 0.12208711355924606, 0...  \n",
      "3938  [[-0.05158155784010887, 0.10700380057096481, -...  \n",
      "2612  [[-0.11040176451206207, 0.0856093317270279, 0....  \n",
      "4259  [[-0.06712516397237778, 0.1756354719400406, 0....  \n",
      "4671  [[-0.0031007544603198767, 0.09306051582098007,...  \n",
      "4134  [[-0.07162205129861832, 0.12586639821529388, 0...  \n",
      "1454  [[-0.1473994255065918, 0.058376193046569824, 0...  \n",
      "1920  [[-0.06484172493219376, 0.05885786935687065, 0...  \n",
      "2177  [[-0.08865635097026825, 0.12472555041313171, 0...  \n",
      "1095  [[0.001048372476361692, 0.008839261718094349, ...  \n",
      "End of training\n",
      "End of first train\n"
     ]
    }
   ],
   "source": [
    "model, df = first_train(train_dir, model_save_path) #será executado\n",
    "# Abaixo são testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(df, df_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 1586 entries, 2469 to 13197\nData columns (total 5 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   Name           1586 non-null   object\n 1   Path           1586 non-null   object\n 2   Image          1586 non-null   object\n 3   Face Location  1586 non-null   object\n 4   Face Encoding  1586 non-null   object\ndtypes: object(5)\nmemory usage: 74.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#Se já definidos\n",
    "model = load_binary(model_save_path)\n",
    "df = pd.read_pickle(df_save_path)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Don_Siegelman', 'Donald_Anderson', 'Donald_Carty', ...,\n",
       "       'Gloria_Macapagal_Arroyo', 'Gloria_Macapagal_Arroyo',\n",
       "       'Gloria_Macapagal_Arroyo'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df[\"Name\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Felipe_Rezende'"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "unk_encode = df['Face Encoding'].iloc[563]\n",
    "unk_loc = df['Face Location'].iloc[563]\n",
    "df['Name'].iloc[563]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Int64Index([ 2469,  8652,  8849,  8249,  8248,  7252,  7253,  7254,  7255,\n",
       "             5806,\n",
       "            ...\n",
       "             3150, 13233, 13202, 13224, 13223, 13201, 13195, 13237, 13196,\n",
       "            13197],\n",
       "           dtype='int64', length=1586)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "y_knn = model.kneighbors(n_neighbors=9)\n",
    "y_knn[1][1]\n",
    "df.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = get_labels(df['Name'].values, y_knn)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Donald_Rumsfeld'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "y_pred = model.predict(unk_encode)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, Path, Image, Face Location, Face Encoding]\n",
       "Index: []"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Path</th>\n      <th>Image</th>\n      <th>Face Location</th>\n      <th>Face Encoding</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "kk = df[df['Name'] == \"Aaron_Eckhart\"]\n",
    "kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_2 = read_dir(train_dir, retrieve_one_image=True)\n",
    "# df_2 = df_2.iloc[:1500, :] #Here because of the Dataset \n",
    "# df_2['Image'] = read_image(df_2['Path'])\n",
    "# print(df_2['Name'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method DataFrame.sort_index of                     Name                                               Path\n",
       "3985     AFelipe_Rezende     archive/lfw-deepfunneled/AFelipe_Rezende/1.jpg\n",
       "3938             AJ_Cook  archive/lfw-deepfunneled/AJ_Cook/AJ_Cook_0001.jpg\n",
       "2612            AJ_Lamas  archive/lfw-deepfunneled/AJ_Lamas/AJ_Lamas_000...\n",
       "4259       Aaron_Eckhart  archive/lfw-deepfunneled/Aaron_Eckhart/Aaron_E...\n",
       "4671         Aaron_Guiel  archive/lfw-deepfunneled/Aaron_Guiel/Aaron_Gui...\n",
       "...                  ...                                                ...\n",
       "3950      Zorica_Radovic  archive/lfw-deepfunneled/Zorica_Radovic/Zorica...\n",
       "4177      Zulfiqar_Ahmed  archive/lfw-deepfunneled/Zulfiqar_Ahmed/Zulfiq...\n",
       "4094        Zumrati_Juma  archive/lfw-deepfunneled/Zumrati_Juma/Zumrati_...\n",
       "5698     Zurab_Tsereteli  archive/lfw-deepfunneled/Zurab_Tsereteli/Zurab...\n",
       "1184  Zydrunas_Ilgauskas  archive/lfw-deepfunneled/Zydrunas_Ilgauskas/Zy...\n",
       "\n",
       "[5750 rows x 2 columns]>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# kk = df_2[df_2['Name'] == \"AFelipe_Rezende\"]\n",
    "# kk\n",
    "df_3 = df_2.sort_values([\"Name\"])\n",
    "df_3.sort_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                              Name  \\\n",
       "3985               AFelipe_Rezende   \n",
       "3938                       AJ_Cook   \n",
       "2612                      AJ_Lamas   \n",
       "4259                 Aaron_Eckhart   \n",
       "4671                   Aaron_Guiel   \n",
       "4134               Aaron_Patterson   \n",
       "1454                 Aaron_Peirsol   \n",
       "1920                    Aaron_Pena   \n",
       "2177                  Aaron_Sorkin   \n",
       "1095                  Aaron_Tippin   \n",
       "4575                     Abba_Eban   \n",
       "1802              Abbas_Kiarostami   \n",
       "1082           Abdel_Aziz_Al-Hakim   \n",
       "2432            Abdel_Madi_Shabneh   \n",
       "3895           Abdel_Nasser_Assidi   \n",
       "2489                Abdoulaye_Wade   \n",
       "2954        Abdul_Majeed_Shobokshi   \n",
       "4738                  Abdul_Rahman   \n",
       "3016             Abdulaziz_Kamilov   \n",
       "4458                      Abdullah   \n",
       "4007         Abdullah_Ahmad_Badawi   \n",
       "58                    Abdullah_Gul   \n",
       "1984              Abdullah_Nasseef   \n",
       "2988           Abdullah_al-Attiyah   \n",
       "4800              Abdullatif_Sener   \n",
       "921                   Abel_Aguilar   \n",
       "979                   Abel_Pacheco   \n",
       "4300  Abid_Hamid_Mahmud_Al-Tikriti   \n",
       "5278                Abner_Martinez   \n",
       "226                 Abraham_Foxman   \n",
       "\n",
       "                                                   Path  \n",
       "3985     archive/lfw-deepfunneled/AFelipe_Rezende/1.jpg  \n",
       "3938  archive/lfw-deepfunneled/AJ_Cook/AJ_Cook_0001.jpg  \n",
       "2612  archive/lfw-deepfunneled/AJ_Lamas/AJ_Lamas_000...  \n",
       "4259  archive/lfw-deepfunneled/Aaron_Eckhart/Aaron_E...  \n",
       "4671  archive/lfw-deepfunneled/Aaron_Guiel/Aaron_Gui...  \n",
       "4134  archive/lfw-deepfunneled/Aaron_Patterson/Aaron...  \n",
       "1454  archive/lfw-deepfunneled/Aaron_Peirsol/Aaron_P...  \n",
       "1920  archive/lfw-deepfunneled/Aaron_Pena/Aaron_Pena...  \n",
       "2177  archive/lfw-deepfunneled/Aaron_Sorkin/Aaron_So...  \n",
       "1095  archive/lfw-deepfunneled/Aaron_Tippin/Aaron_Ti...  \n",
       "4575  archive/lfw-deepfunneled/Abba_Eban/Abba_Eban_0...  \n",
       "1802  archive/lfw-deepfunneled/Abbas_Kiarostami/Abba...  \n",
       "1082  archive/lfw-deepfunneled/Abdel_Aziz_Al-Hakim/A...  \n",
       "2432  archive/lfw-deepfunneled/Abdel_Madi_Shabneh/Ab...  \n",
       "3895  archive/lfw-deepfunneled/Abdel_Nasser_Assidi/A...  \n",
       "2489  archive/lfw-deepfunneled/Abdoulaye_Wade/Abdoul...  \n",
       "2954  archive/lfw-deepfunneled/Abdul_Majeed_Shoboksh...  \n",
       "4738  archive/lfw-deepfunneled/Abdul_Rahman/Abdul_Ra...  \n",
       "3016  archive/lfw-deepfunneled/Abdulaziz_Kamilov/Abd...  \n",
       "4458  archive/lfw-deepfunneled/Abdullah/Abdullah_000...  \n",
       "4007  archive/lfw-deepfunneled/Abdullah_Ahmad_Badawi...  \n",
       "58    archive/lfw-deepfunneled/Abdullah_Gul/Abdullah...  \n",
       "1984  archive/lfw-deepfunneled/Abdullah_Nasseef/Abdu...  \n",
       "2988  archive/lfw-deepfunneled/Abdullah_al-Attiyah/A...  \n",
       "4800  archive/lfw-deepfunneled/Abdullatif_Sener/Abdu...  \n",
       "921   archive/lfw-deepfunneled/Abel_Aguilar/Abel_Agu...  \n",
       "979   archive/lfw-deepfunneled/Abel_Pacheco/Abel_Pac...  \n",
       "4300  archive/lfw-deepfunneled/Abid_Hamid_Mahmud_Al-...  \n",
       "5278  archive/lfw-deepfunneled/Abner_Martinez/Abner_...  \n",
       "226   archive/lfw-deepfunneled/Abraham_Foxman/Abraha...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3985</th>\n      <td>AFelipe_Rezende</td>\n      <td>archive/lfw-deepfunneled/AFelipe_Rezende/1.jpg</td>\n    </tr>\n    <tr>\n      <th>3938</th>\n      <td>AJ_Cook</td>\n      <td>archive/lfw-deepfunneled/AJ_Cook/AJ_Cook_0001.jpg</td>\n    </tr>\n    <tr>\n      <th>2612</th>\n      <td>AJ_Lamas</td>\n      <td>archive/lfw-deepfunneled/AJ_Lamas/AJ_Lamas_000...</td>\n    </tr>\n    <tr>\n      <th>4259</th>\n      <td>Aaron_Eckhart</td>\n      <td>archive/lfw-deepfunneled/Aaron_Eckhart/Aaron_E...</td>\n    </tr>\n    <tr>\n      <th>4671</th>\n      <td>Aaron_Guiel</td>\n      <td>archive/lfw-deepfunneled/Aaron_Guiel/Aaron_Gui...</td>\n    </tr>\n    <tr>\n      <th>4134</th>\n      <td>Aaron_Patterson</td>\n      <td>archive/lfw-deepfunneled/Aaron_Patterson/Aaron...</td>\n    </tr>\n    <tr>\n      <th>1454</th>\n      <td>Aaron_Peirsol</td>\n      <td>archive/lfw-deepfunneled/Aaron_Peirsol/Aaron_P...</td>\n    </tr>\n    <tr>\n      <th>1920</th>\n      <td>Aaron_Pena</td>\n      <td>archive/lfw-deepfunneled/Aaron_Pena/Aaron_Pena...</td>\n    </tr>\n    <tr>\n      <th>2177</th>\n      <td>Aaron_Sorkin</td>\n      <td>archive/lfw-deepfunneled/Aaron_Sorkin/Aaron_So...</td>\n    </tr>\n    <tr>\n      <th>1095</th>\n      <td>Aaron_Tippin</td>\n      <td>archive/lfw-deepfunneled/Aaron_Tippin/Aaron_Ti...</td>\n    </tr>\n    <tr>\n      <th>4575</th>\n      <td>Abba_Eban</td>\n      <td>archive/lfw-deepfunneled/Abba_Eban/Abba_Eban_0...</td>\n    </tr>\n    <tr>\n      <th>1802</th>\n      <td>Abbas_Kiarostami</td>\n      <td>archive/lfw-deepfunneled/Abbas_Kiarostami/Abba...</td>\n    </tr>\n    <tr>\n      <th>1082</th>\n      <td>Abdel_Aziz_Al-Hakim</td>\n      <td>archive/lfw-deepfunneled/Abdel_Aziz_Al-Hakim/A...</td>\n    </tr>\n    <tr>\n      <th>2432</th>\n      <td>Abdel_Madi_Shabneh</td>\n      <td>archive/lfw-deepfunneled/Abdel_Madi_Shabneh/Ab...</td>\n    </tr>\n    <tr>\n      <th>3895</th>\n      <td>Abdel_Nasser_Assidi</td>\n      <td>archive/lfw-deepfunneled/Abdel_Nasser_Assidi/A...</td>\n    </tr>\n    <tr>\n      <th>2489</th>\n      <td>Abdoulaye_Wade</td>\n      <td>archive/lfw-deepfunneled/Abdoulaye_Wade/Abdoul...</td>\n    </tr>\n    <tr>\n      <th>2954</th>\n      <td>Abdul_Majeed_Shobokshi</td>\n      <td>archive/lfw-deepfunneled/Abdul_Majeed_Shoboksh...</td>\n    </tr>\n    <tr>\n      <th>4738</th>\n      <td>Abdul_Rahman</td>\n      <td>archive/lfw-deepfunneled/Abdul_Rahman/Abdul_Ra...</td>\n    </tr>\n    <tr>\n      <th>3016</th>\n      <td>Abdulaziz_Kamilov</td>\n      <td>archive/lfw-deepfunneled/Abdulaziz_Kamilov/Abd...</td>\n    </tr>\n    <tr>\n      <th>4458</th>\n      <td>Abdullah</td>\n      <td>archive/lfw-deepfunneled/Abdullah/Abdullah_000...</td>\n    </tr>\n    <tr>\n      <th>4007</th>\n      <td>Abdullah_Ahmad_Badawi</td>\n      <td>archive/lfw-deepfunneled/Abdullah_Ahmad_Badawi...</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>Abdullah_Gul</td>\n      <td>archive/lfw-deepfunneled/Abdullah_Gul/Abdullah...</td>\n    </tr>\n    <tr>\n      <th>1984</th>\n      <td>Abdullah_Nasseef</td>\n      <td>archive/lfw-deepfunneled/Abdullah_Nasseef/Abdu...</td>\n    </tr>\n    <tr>\n      <th>2988</th>\n      <td>Abdullah_al-Attiyah</td>\n      <td>archive/lfw-deepfunneled/Abdullah_al-Attiyah/A...</td>\n    </tr>\n    <tr>\n      <th>4800</th>\n      <td>Abdullatif_Sener</td>\n      <td>archive/lfw-deepfunneled/Abdullatif_Sener/Abdu...</td>\n    </tr>\n    <tr>\n      <th>921</th>\n      <td>Abel_Aguilar</td>\n      <td>archive/lfw-deepfunneled/Abel_Aguilar/Abel_Agu...</td>\n    </tr>\n    <tr>\n      <th>979</th>\n      <td>Abel_Pacheco</td>\n      <td>archive/lfw-deepfunneled/Abel_Pacheco/Abel_Pac...</td>\n    </tr>\n    <tr>\n      <th>4300</th>\n      <td>Abid_Hamid_Mahmud_Al-Tikriti</td>\n      <td>archive/lfw-deepfunneled/Abid_Hamid_Mahmud_Al-...</td>\n    </tr>\n    <tr>\n      <th>5278</th>\n      <td>Abner_Martinez</td>\n      <td>archive/lfw-deepfunneled/Abner_Martinez/Abner_...</td>\n    </tr>\n    <tr>\n      <th>226</th>\n      <td>Abraham_Foxman</td>\n      <td>archive/lfw-deepfunneled/Abraham_Foxman/Abraha...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "df_3.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fim encode\n"
     ]
    }
   ],
   "source": [
    "df[\"Face Location\"] = df[\"Image\"].apply(lambda x: fr.face_locations(x, 2, model=\"hog\"))\n",
    "df[\"Face Encoding\"] = df.apply(lambda x: fr.face_encodings(x[\"Image\"], x[\"Face Location\"]), axis=1)\n",
    "df.to_pickle(df_save_path) #parquet does not support 2D arrays\n",
    "print(\"Fim encode\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(df_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 1405 entries, 0 to 1499\nData columns (total 5 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   Name           1405 non-null   object\n 1   Path           1405 non-null   object\n 2   Image          1405 non-null   object\n 3   Face Location  1405 non-null   object\n 4   Face Encoding  1405 non-null   object\ndtypes: object(5)\nmemory usage: 65.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(df_save_path)\n",
    "df = df[df.apply(lambda x: len(x['Face Encoding']) == 1, axis= 1)]\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing background faces\n",
    "# sum_list_loc_m = []\n",
    "# result = zip(df_2['Face Location'][:13], df_2['Face Encoding'][:13])\n",
    "# for face_location, face_encoding in result:\n",
    "#     if len(face_location) > 1:\n",
    "#         mydict = dict(zip(face_location, face_encoding))\n",
    "#         sorted_dict = dict()\n",
    "#         for key in sorted(mydict, key=lambda x: sum(x), reverse=True):\n",
    "#             sorted_dict.update({key: mydict[key]})\n",
    "\n",
    "# first_item = next(iter(mydict_2.items()))\n",
    "# first_face_location, first_face_encoding = first_item\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "uncaps_encode = []\n",
    "for elem in df['Face Encoding'].values:\n",
    "    uncaps_encode.append(elem[0]) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "End of training\n",
      "['Tom_Watson']\n"
     ]
    }
   ],
   "source": [
    "#Devo retornar um array com as posições de cada face e seus nomes para que o draw possa iterar neste, mesmo que seja unitário\n",
    "#No momento do cadastro a screenshot deverá ser validada, para que se armazene somente a foto que houver apenas uma face\n",
    "model = knn_train(uncaps_encode, df['Name'])\n",
    "y_pred = model.predict(unk_encode)\n",
    "print(y_pred)\n",
    "# y_pred = model.predict(frame_encoded)\n",
    "# candidate = df[df['Name'] == y_pred]\n",
    "# face_distance = can\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "#GET LABELS and verify face distance\n",
    "\n",
    "candidates = np.array([[563, 565, 564, 763, 567, 528]])\n",
    "candidates_subset = df.iloc[candidates[0]]\n",
    "distances = []\n",
    "for encode in candidates_subset['Face Encoding']:\n",
    "    distances.append(np.linalg.norm(unk_encode[0] - encode[0]))\n",
    "\n",
    "count = len([dst for dst in distances if dst > 0.5])\n",
    "count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}